{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams if GPU is available\n",
    "if tf.test.is_gpu_available():\n",
    "    BATCH_SIZE = 512  # Number of examples used in each iteration\n",
    "    EPOCHS = 5  # Number of passes through entire dataset\n",
    "    MAX_LEN = 75  # Max length of review (in words)\n",
    "    EMBEDDING = 40  # Dimension of word embedding vector\n",
    "\n",
    "    \n",
    "# Hyperparams for CPU training\n",
    "else:\n",
    "    BATCH_SIZE = 32\n",
    "    EPOCHS = 5\n",
    "    MAX_LEN = 75\n",
    "    EMBEDDING = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"ner_dataset_altered.csv\", encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[data['Word']=='at']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfSeries = [pd.Series(['Sentence: 47960','Dr','NNP','B-prov'],index=data.columns),\n",
    "                pd.Series(['Sentence: 47960','Gregory','NNP','I-prov'],index=data.columns),\n",
    "                pd.Series(['Sentence: 47960','M','NNP','I-prov'],index=data.columns),\n",
    "                pd.Series(['Sentence: 47960','Cowan','NNP','I-prov'],index=data.columns),\n",
    "                pd.Series(['Sentence: 47960','is','VBZ','O'],index=data.columns),\n",
    "                pd.Series(['Sentence: 47960','an','DT','O'],index=data.columns),\n",
    "                pd.Series(['Sentence: 47960','Immunologist','NN','B-spec'],index=data.columns),\n",
    "                pd.Series(['Sentence: 47960','at ','IN','O'],index=data.columns),\n",
    "                pd.Series(['Sentence: 47960','Fortis','NNP','B-org'],index=data.columns),\n",
    "                pd.Series(['Sentence: 47960','Hospital','NNP','I-org'],index=data.columns),\n",
    "                pd.Series(['Sentence: 47961','Dr','NNP','B-prov'],index=data.columns),\n",
    "                pd.Series(['Sentence: 47961','Debra','NNP','I-prov'],index=data.columns),\n",
    "                pd.Series(['Sentence: 47961','H','NNP','I-prov'],index=data.columns),\n",
    "                pd.Series(['Sentence: 47961','Mescher','NNP','I-prov'],index=data.columns),\n",
    "                pd.Series(['Sentence: 47961','is','VBZ','O'],index=data.columns),\n",
    "                pd.Series(['Sentence: 47961','an ','DT','O'],index=data.columns),\n",
    "                pd.Series(['Sentence: 47961','Internist','NN','B-spec'],index=data.columns),\n",
    "                pd.Series(['Sentence: 47962','Jordan','NNP','B-prov'],index=data.columns),\n",
    "                pd.Series(['Sentence: 47962','A','NNP','I-prov'],index=data.columns),\n",
    "                pd.Series(['Sentence: 47962','Sennett','NNP','I-prov'],index=data.columns),\n",
    "                pd.Series(['Sentence: 47962','is','VBZ','O'],index=data.columns),\n",
    "                pd.Series(['Sentence: 47962','an','DT','O'],index=data.columns),\n",
    "                pd.Series(['Sentence: 47962','Endocrinologist','NN','B-spec'],index=data.columns)\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass a list of series to the append() to add multiple rows\n",
    "data = data.append(listOfSeries , ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sentence: 1', 'Sentence: 2', 'Sentence: 3', ...,\n",
       "       'Sentence: 47957', 'Sentence: 47958', 'Sentence: 47959'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Sentence #'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.groupby(['Sentence #']))\n",
    "print(\"Number of sentences: \", len(data.groupby(['Sentence #'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in the dataset:  35178\n",
      "Number of total words in the dataset:  1048575\n"
     ]
    }
   ],
   "source": [
    "words = list(set(data['Word'].values))\n",
    "n_words = len(words)\n",
    "print(\"Number of unique words in the dataset: \", n_words)\n",
    "print(\"Number of total words in the dataset: \", len(list(data['Word'].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-geo', 'I-tim', 'B-geo', 'B-tim', 'O', 'B-gpe', 'B-eve', 'B-per', 'B-art', 'I-gpe', 'B-nat', 'I-eve', 'B-org', 'I-nat', 'B-prov', 'I-art', 'I-org', 'I-prov']\n",
      "Number of tags in the dataset:  18\n"
     ]
    }
   ],
   "source": [
    "tags = list(set(data['Tag'].values))\n",
    "n_tags = len(tags)\n",
    "print(tags)\n",
    "print(\"Number of tags in the dataset: \", n_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_func = lambda s:[(w,p,t) for w,p,t in zip(s[\"Word\"].values.tolist(), s[\"POS\"].values.tolist(), s[\"Tag\"].values.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Thousands', 'NNS', 'O')\n",
      "('of', 'IN', 'O')\n",
      "('demonstrators', 'NNS', 'O')\n",
      "('have', 'VBP', 'O')\n",
      "('marched', 'VBN', 'O')\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ad9463b05ca8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'marched'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in zip(data[\"Word\"].values.tolist(), data[\"POS\"].values.tolist(), data[\"Tag\"].values.tolist()):\n",
    "    print(i)    \n",
    "    if i[0] == 'marched':\n",
    "        assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \"\"\"\n",
    "    Class to get sentence in format : [(Token, PartOfSpeech,Tag),()]\n",
    "    \"\"\"\n",
    "    def __init__(self,data):\n",
    "        \"\"\"\n",
    "        data : pandas dataframe\n",
    "        \"\"\"\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        \n",
    "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "        print(len(self.sentences))\n",
    "        print(self.sentences[-1])\n",
    "        \n",
    "    def get_next(self):\n",
    "        \"\"\"Return One Sentence\"\"\"\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47959\n",
      "[('The', 'DT', 'O'), ('United', 'NNP', 'B-org'), ('Nations', 'NNP', 'I-org'), ('is', 'VBZ', 'O'), ('praising', 'VBG', 'O'), ('the', 'DT', 'O'), ('use', 'NN', 'O'), ('of', 'IN', 'O'), ('military', 'JJ', 'O'), ('helicopters', 'NNS', 'O'), ('to', 'TO', 'O'), ('drop', 'VB', 'O'), ('food', 'NN', 'O'), ('and', 'CC', 'O'), ('rescue', 'NN', 'O'), ('survivors', 'NNS', 'O'), ('in', 'IN', 'O'), ('tsunami-ravaged', 'JJ', 'B-tim'), ('Indonesia', 'NNP', 'I-tim'), (',', ',', 'O'), ('saying', 'VBG', 'O'), ('the', 'DT', 'O'), ('aircraft', 'NN', 'O'), ('are', 'VBP', 'O'), ('\"', '``', 'O'), ('worth', 'IN', 'O'), ('their', 'PRP$', 'O'), ('weight', 'NN', 'O'), ('in', 'IN', 'O'), ('gold', 'NN', 'O'), ('.', '.', 'O'), ('\"', '``', 'O')]\n"
     ]
    }
   ],
   "source": [
    "getter = SentenceGetter(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(getter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = getter.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is what a sentence looks like:\n",
      "[('Thousands', 'NNS', 'O'), ('of', 'IN', 'O'), ('demonstrators', 'NNS', 'O'), ('have', 'VBP', 'O'), ('marched', 'VBN', 'O'), ('through', 'IN', 'O'), ('London', 'NNP', 'B-geo'), ('to', 'TO', 'O'), ('protest', 'VB', 'O'), ('the', 'DT', 'O'), ('war', 'NN', 'O'), ('in', 'IN', 'O'), ('Iraq', 'NNP', 'B-geo'), ('and', 'CC', 'O'), ('demand', 'VB', 'O'), ('the', 'DT', 'O'), ('withdrawal', 'NN', 'O'), ('of', 'IN', 'O'), ('British', 'JJ', 'B-gpe'), ('troops', 'NNS', 'O'), ('from', 'IN', 'O'), ('that', 'DT', 'O'), ('country', 'NN', 'O'), ('.', '.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "print('This is what a sentence looks like:')\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47959\n"
     ]
    }
   ],
   "source": [
    "# Get all the sentences\n",
    "sentences = getter.sentences\n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot sentence by lenght\n",
    "plt.hist([len(s) for s in sentences], bins=50)\n",
    "plt.title('Token per sentence')\n",
    "plt.xlabel('Len (number of token)')\n",
    "plt.ylabel('# samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Data Preprocessing\n",
    "Before feeding the data into the model, we have to preprocess the text.\n",
    "\n",
    "We will use the word2idx dictionary to convert each word to a corresponding integer ID and the tag2idx to do the same for the labels. Representing words as integers saves a lot of memory!\n",
    "\n",
    "In order to feed the text into our Bi-LSTM-CRF, all texts should be the same length. We ensure this using the sequence.pad_sequences() method and MAX_LEN variable. \n",
    "\n",
    "All texts longer than MAX_LEN are truncated and shorter texts are padded to get them to the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary Key:word --> Value:token_index\n",
    "# The first 2 entries are reserved for PAD and UNK\n",
    "word2idx = {w:i+2 for i,w in enumerate(words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx['UNK'] = 1 # Unknown words\n",
    "word2idx['PAD'] = 0 # Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word2idx['of'])\n",
    "print(word2idx['through'])\n",
    "print(word2idx['George'])\n",
    "print(word2idx['Endocrinologist'])\n",
    "print(word2idx['andy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary Key:token_index  --> Value:word\n",
    "idx2word = {i:w for w,i in word2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(idx2word[0])\n",
    "print(idx2word[1])\n",
    "print(idx2word[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary Key:Label/Tag --> Value:tag_index\n",
    "# The first entry is reserved for PAD\n",
    "tag2idx = {t: i+1 for i,t in enumerate(tags)}\n",
    "tag2idx[\"PAD\"] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary Key:tag_index --> Value:Label/Tag\n",
    "idx2tag = {i:w for w,i in tag2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tag2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(idx2tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The word Obama is identified by the index: {}\".format(word2idx[\"Obama\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The labels B-geo(which defines Geopraphical Enitities) is identified by the index: {}\".format(tag2idx[\"B-geo\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The labels B-prov(which defines Providers) is identified by the index: {}\".format(tag2idx[\"B-prov\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each sentence from list of tokens to list of word index\n",
    "X = [[word2idx[w[0]] for w in s] for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X))\n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding each sentence to have the same length\n",
    "X = pad_sequences(maxlen=MAX_LEN, sequences=X, padding='post', value=word2idx[\"PAD\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Tag/Label to tag_index\n",
    "y = [[tag2idx[w[2]] for w in s] for s in sentences]\n",
    "# Padding each sentence to have the same length\n",
    "y = pad_sequences(maxlen=MAX_LEN, sequences=y, padding=\"post\", value=tag2idx[\"PAD\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot encode\n",
    "y = [to_categorical(y=i, num_classes=n_tags+1) for i in y] # n_tags+1(PAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y[0][0])\n",
    "print(len(y[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_train.shape[0] + X_test.shape[0])\n",
    "print(np.array(y_train).shape)\n",
    "print(np.array(y_test).shape)\n",
    "print(np.array(y_train).shape[0] + np.array(y_test).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0 = ' '.join([w[0] for w in sentences[0]])\n",
    "print('Raw Sample: ')\n",
    "print(w0)\n",
    "print(len(w0))\n",
    "print('\\n')\n",
    "print('After processing, sample:')\n",
    "print(X[0])\n",
    "print(len(X[0]))\n",
    "print('\\n')\n",
    "for i in X[0]:\n",
    "    print(i, idx2word[i])\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2 = ' '.join([w[2] for w in sentences[0]])\n",
    "ws2 = [w[2] for w in sentences[0]]\n",
    "print('Raw Label: ')\n",
    "print(w2)\n",
    "print(ws2)\n",
    "print(len(ws2))\n",
    "print(type(ws2))\n",
    "print('\\n')\n",
    "print('After processing, labels:')\n",
    "print(len(y[0]))\n",
    "for i in range(len(ws2)):\n",
    "    print(ws2[i],y[0][i])\n",
    "    \n",
    "print(y[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install extra-dependencies\n",
    "! pip -q install git+https://www.github.com/keras-team/keras-contrib.git sklearn-crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ikscare/anaconda3/envs/py36/lib/python3.6/site-packages/keras_contrib/layers/crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
      "  warnings.warn('CRF.loss_function is deprecated '\n",
      "/home/ikscare/anaconda3/envs/py36/lib/python3.6/site-packages/keras_contrib/layers/crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
      "  warnings.warn('CRF.accuracy is deprecated and it '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 75, 20)            703600    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 75, 100)           28400     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 75, 50)            5050      \n",
      "_________________________________________________________________\n",
      "crf_1 (CRF)                  (None, 75, 19)            1368      \n",
      "=================================================================\n",
      "Total params: 738,418\n",
      "Trainable params: 738,418\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from keras_contrib.layers import CRF\n",
    "\n",
    "# Model definition\n",
    "input = Input(shape=(MAX_LEN,))\n",
    "model = Embedding(input_dim=n_words+2, output_dim=EMBEDDING, # n_words + 2 (PAD & UNK)  \n",
    "                  input_length=MAX_LEN, mask_zero=True)(input)  # default: 20-dim embedding\n",
    "model = Bidirectional(LSTM(units=50, return_sequences=True,\n",
    "                           recurrent_dropout=0.1))(model)  # variational biLSTM\n",
    "model = TimeDistributed(Dense(50, activation=\"relu\"))(model)  # a dense layer as suggested by neuralNer\n",
    "crf = CRF(n_tags+1)  # CRF layer, n_tags+1(PAD)\n",
    "out = crf(model)  # output\n",
    "\n",
    "model = Model(input, out)\n",
    "model.compile(optimizer=\"rmsprop\", loss=crf.loss_function, metrics=[crf.accuracy])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Accuracy isn't the best metric to choose for evaluating this type of task because most of the time it will correctly predict 'O' or 'PAD' without identifing the important Tags, which are the ones we are interested in. So after training for some epochs, we can monitor the precision, recall and f1-score for each of the Tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38846 samples, validate on 4317 samples\n",
      "Epoch 1/5\n",
      " - 169s - loss: 9.2662 - crf_viterbi_accuracy: 0.9027 - val_loss: 9.1399 - val_crf_viterbi_accuracy: 0.9453\n",
      "Epoch 2/5\n",
      " - 164s - loss: 9.0332 - crf_viterbi_accuracy: 0.9562 - val_loss: 9.0880 - val_crf_viterbi_accuracy: 0.9607\n",
      "Epoch 3/5\n",
      " - 165s - loss: 9.0015 - crf_viterbi_accuracy: 0.9655 - val_loss: 9.0729 - val_crf_viterbi_accuracy: 0.9647\n",
      "Epoch 4/5\n",
      " - 165s - loss: 8.9900 - crf_viterbi_accuracy: 0.9687 - val_loss: 9.0682 - val_crf_viterbi_accuracy: 0.9656\n",
      "Epoch 5/5\n",
      " - 164s - loss: 8.9838 - crf_viterbi_accuracy: 0.9707 - val_loss: 9.0676 - val_crf_viterbi_accuracy: 0.9659\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, np.array(y_train), batch_size=BATCH_SIZE, epochs=EPOCHS,\n",
    "                    validation_split=0.1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval\n",
    "pred_cat = model.predict(X_test)\n",
    "pred = np.argmax(pred_cat, axis=-1)\n",
    "y_test_true = np.argmax(y_test, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_crfsuite.metrics import flat_classification_report\n",
    "\n",
    "# Convert the index to tag\n",
    "pred_tag = [[idx2tag[i] for i in row] for row in pred]\n",
    "y_test_true_tag = [[idx2tag[i] for i in row] for row in y_test_true] \n",
    "\n",
    "report = flat_classification_report(y_pred=pred_tag, y_true=y_test_true_tag)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.randint(0,X_test.shape[0]) # choose a random number between 0 and len(X_te)\n",
    "p = model.predict(np.array([X_test[i]]))\n",
    "p = np.argmax(p, axis=-1)\n",
    "true = np.argmax(y_test[i], -1)\n",
    "\n",
    "print(\"Sample number {} of {} (Test Set)\".format(i, X_test.shape[0]))\n",
    "# Visualization\n",
    "print(\"{:15}||{:5}||{}\".format(\"Word\", \"True\", \"Pred\"))\n",
    "print(30 * \"=\")\n",
    "for w, t, pred in zip(X_test[i], true, p[0]):\n",
    "    if w != 0:\n",
    "        print(\"{:15}: {:5} {}\".format(words[w-2], idx2tag[t], idx2tag[pred]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact_manual\n",
    "from ipywidgets import widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "# Custom Tokenizer\n",
    "re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
    "\n",
    "def tokenize(s): \n",
    "    return re_tok.sub(r' \\1 ', s).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(sentence):\n",
    "    test_sentence = tokenize(sentence) # Tokenization\n",
    "    # Preprocessing\n",
    "    x_test_sent = pad_sequences(sequences=[[word2idx.get(w, 0) for w in test_sentence]],\n",
    "                            padding=\"post\", value=word2idx[\"PAD\"], maxlen=MAX_LEN)\n",
    "    # Evaluation\n",
    "    p = model.predict(np.array([x_test_sent[0]]))\n",
    "    p = np.argmax(p, axis=-1)\n",
    "    # Visualization\n",
    "    print(\"{:15}||{}\".format(\"Word\", \"Prediction\"))\n",
    "    print(30 * \"=\")\n",
    "    for w, pred in zip(test_sentence, p[0]):\n",
    "        print(\"{:15}: {:5}\".format(w, idx2tag[pred]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact_manual(get_prediction, sentence=widgets.Textarea(placeholder='Type your sentence here'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prediction(\"Obama was the president of USA.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prediction(\"The 1906 San Francisco earthquake was the biggest earthquake that has ever hit San Francisco on April 18, 1906\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prediction(\"Next Monday is Christmas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prediction(\"al Qaeda is a terrorist organization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prediction(\"President Nasser presided over the audience\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prediction(\"John Smith works at the United Nations every Saturday\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prediction(\"Andy Garcia works at the United Nations every Saturday\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prediction(\"Gregory M Cowan is an Immunologist at Fortis Hospital\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prediction(\"Debra H Mescher is an Internist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prediction('Nikola Gruevski Khin Nyunt Smith works at the United Nations every Saturday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prediction('David Richards was a great man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str = (\"Colonoscopy Sigmoidoscopy Large Bowel Polyps Diverticulitis Crohn Gastritis Enteroscopy Colon Endoscope \"\n",
    "\"Patient Name :  Pamela Woodard \"\n",
    "\"DOB : 11/09/1996 \" \n",
    "\"Date : 21/10/18 \"\n",
    "\"Order orders Appointment Schedule Requesting Provider Physician Prescriber Surgery Clearance Medical clearance Supply Supplies \"\n",
    "\"Christian Chu  MD \"\n",
    "\"WeServeEveryone Clinic\")\n",
    "\n",
    "get_prediction(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
